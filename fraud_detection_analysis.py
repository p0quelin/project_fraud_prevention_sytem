"""
Fraud Detection in Payment Systems - Comprehensive Analysis
==========================================================

This script provides a comprehensive analysis of payment fraud detection 
using various machine learning techniques. It loads data generated by 
generator.py and demonstrates:

1. Data exploration and visualization
2. Feature engineering for fraud detection
3. Model development and comparison
4. Advanced fraud detection techniques
5. Evaluation metrics specific to fraud detection
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import time
import warnings
import pickle

# Machine Learning libraries
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import (classification_report, confusion_matrix, roc_curve, 
                            roc_auc_score, precision_recall_curve, average_precision_score, 
                            f1_score, precision_score, recall_score)
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
import xgboost as xgb
import lightgbm as lgb
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as IMBPipeline

# Settings
pd.set_option('display.max_columns', None)
warnings.filterwarnings('ignore')

def load_data():
    """Load data generated by generator.py"""
    print("Loading transaction data...")
    transactions = pd.read_csv('data/transactions_df.csv')
    customer_profiles = pd.read_csv('data/customer_profiles_table.csv')
    terminal_profiles = pd.read_csv('data/terminal_profiles_table.csv')
    
    # Convert TX_DATETIME to datetime
    transactions['TX_DATETIME'] = pd.to_datetime(transactions['TX_DATETIME'])
    
    # Fix available_terminals (convert string representation to actual list)
    customer_profiles['available_terminals'] = customer_profiles['available_terminals'].apply(
        lambda x: [int(i) for i in x.strip('[]').split(',')] if isinstance(x, str) else [])
    
    print(f"Dataset information:")
    print(f"Transactions: {transactions.shape[0]} rows, {transactions.shape[1]} columns")
    print(f"Customers: {customer_profiles.shape[0]}")
    print(f"Terminals: {terminal_profiles.shape[0]}")
    
    # Check for fraud distribution
    fraud_count = transactions['TX_FRAUD'].sum()
    total_count = transactions.shape[0]
    print(f"\nFraud statistics:")
    print(f"Fraudulent transactions: {fraud_count} ({fraud_count/total_count:.2%})")
    print(f"Legitimate transactions: {total_count - fraud_count} ({(total_count-fraud_count)/total_count:.2%})")
    
    return transactions, customer_profiles, terminal_profiles

def exploratory_analysis(transactions, customer_profiles, terminal_profiles):
    """Perform exploratory data analysis"""
    print("\n--- Performing Exploratory Analysis ---")
    
    # Analyze fraud scenarios
    fraud_data = transactions[transactions['TX_FRAUD'] == 1]
    fraud_scenarios = fraud_data['TX_FRAUD_SCENARIO'].value_counts().sort_index()
    scenario_names = {
        1: 'Anomalous Amount',
        2: 'Compromised Terminal',
        3: 'Card-Not-Present',
        4: 'Quick Cash-Out'
    }
    
    print("\nFraud Scenario Distribution:")
    for scenario_id, count in fraud_scenarios.items():
        scenario_name = scenario_names.get(scenario_id, f'Unknown ({scenario_id})')
        percentage = count / fraud_data.shape[0] * 100
        print(f"  {scenario_name}: {count} transactions ({percentage:.1f}%)")
    
    # Create a visualization for fraud scenarios
    plt.figure(figsize=(10, 6))
    scenario_df = pd.DataFrame({
        'scenario': [scenario_names.get(i, f'Unknown ({i})') for i in fraud_scenarios.index],
        'count': fraud_scenarios.values,
        'percentage': [count / fraud_data.shape[0] * 100 for count in fraud_scenarios.values]
    })
    
    ax = sns.barplot(x='scenario', y='count', data=scenario_df, palette='viridis')
    
    # Add percentage labels
    for i, p in enumerate(ax.patches):
        ax.annotate(f'{scenario_df["percentage"].iloc[i]:.1f}%', 
                   (p.get_x() + p.get_width() / 2., p.get_height()),
                   ha = 'center', va = 'bottom', fontsize=11)
    
    plt.title('Distribution of Fraud Scenarios', fontsize=14)
    plt.xlabel('Fraud Scenario Type', fontsize=12)
    plt.ylabel('Number of Transactions', fontsize=12)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('images/fraud_scenarios.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # Analyze fraud by terminal type
    tx_with_terminal = pd.merge(transactions, 
                               terminal_profiles[['TERMINAL_ID', 'terminal_type']], 
                               on='TERMINAL_ID', how='left')
    
    terminal_stats = tx_with_terminal.groupby('terminal_type').agg(
        total_count=('TX_FRAUD', 'count'),
        fraud_count=('TX_FRAUD', 'sum')
    ).reset_index()
    terminal_stats['fraud_rate'] = terminal_stats['fraud_count'] / terminal_stats['total_count'] * 100
    
    print("\nFraud Rate by Terminal Type:")
    for _, row in terminal_stats.sort_values('fraud_rate', ascending=False).iterrows():
        print(f"  {row['terminal_type']}: {row['fraud_rate']:.2f}% ({row['fraud_count']} out of {row['total_count']})")
    
    # Create a visualization for terminal fraud rates
    plt.figure(figsize=(10, 6))
    terminal_stats_sorted = terminal_stats.sort_values('fraud_rate', ascending=False)
    
    ax = sns.barplot(x='terminal_type', y='fraud_rate', data=terminal_stats_sorted, palette='viridis')
    
    # Add percentage labels
    for i, p in enumerate(ax.patches):
        ax.annotate(f'{p.get_height():.2f}%', 
                   (p.get_x() + p.get_width() / 2., p.get_height()),
                   ha = 'center', va = 'bottom', fontsize=11)
    
    plt.title('Fraud Rate by Terminal Type', fontsize=14)
    plt.xlabel('Terminal Type', fontsize=12)
    plt.ylabel('Fraud Rate (%)', fontsize=12)
    plt.tight_layout()
    plt.savefig('images/terminal_fraud_rates.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # Transaction amount statistics
    print("\nTransaction Amount Statistics:")
    legitimate_amount = transactions[transactions['TX_FRAUD'] == 0]['TX_AMOUNT']
    fraud_amount = transactions[transactions['TX_FRAUD'] == 1]['TX_AMOUNT']
    
    print(f"  Legitimate transactions: Avg=${legitimate_amount.mean():.2f}, Median=${legitimate_amount.median():.2f}")
    print(f"  Fraudulent transactions: Avg=${fraud_amount.mean():.2f}, Median=${fraud_amount.median():.2f}")
    
    # Create a visualization for amount distribution
    plt.figure(figsize=(10, 6))
    
    # Create a DataFrame for easier plotting
    amount_data = pd.DataFrame({
        'Amount': pd.concat([legitimate_amount, fraud_amount]),
        'Type': ['Legitimate'] * len(legitimate_amount) + ['Fraudulent'] * len(fraud_amount)
    })
    
    # Plot boxplot with log scale
    sns.boxplot(x='Type', y='Amount', data=amount_data, palette='viridis')
    plt.yscale('log')
    plt.title('Transaction Amount Distribution (Log Scale)', fontsize=14)
    plt.xlabel('Transaction Type', fontsize=12)
    plt.ylabel('Amount ($)', fontsize=12)
    plt.tight_layout()
    plt.savefig('images/amount_distribution.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    return tx_with_terminal

def engineer_features(transactions, customer_profiles, terminal_profiles):
    """Generate features for fraud detection model"""
    print("\n--- Performing Feature Engineering ---")
    
    # Start with a copy of the transactions to avoid modifying the original
    df = transactions.copy()
    
    # Ensure datetime format
    if not pd.api.types.is_datetime64_any_dtype(df['TX_DATETIME']):
        df['TX_DATETIME'] = pd.to_datetime(df['TX_DATETIME'])
    
    # Sort by customer and datetime for sequential features
    df = df.sort_values(['CUSTOMER_ID', 'TX_DATETIME']).reset_index(drop=True)
    
    # 1. TEMPORAL FEATURES
    print("  Adding temporal features...")
    # Extract time components
    df['hour'] = df['TX_DATETIME'].dt.hour
    df['day_of_week'] = df['TX_DATETIME'].dt.dayofweek
    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
    df['day_of_month'] = df['TX_DATETIME'].dt.day
    
    # Time periods
    conditions = [
        (df['hour'] >= 0) & (df['hour'] < 6),
        (df['hour'] >= 6) & (df['hour'] < 12),
        (df['hour'] >= 12) & (df['hour'] < 18),
        (df['hour'] >= 18) & (df['hour'] <= 23)
    ]
    time_periods = ['late_night', 'morning', 'afternoon', 'evening']
    df['time_period'] = np.select(conditions, time_periods, default='unknown')
    
    # Flag night hours (higher fraud risk)
    df['is_night'] = ((df['hour'] >= 0) & (df['hour'] < 6)).astype(int)
    
    # Month-end flag (often higher spending)
    df['is_month_end'] = (df['day_of_month'] >= 25).astype(int)
    
    # 2. CUSTOMER BEHAVIOR FEATURES
    print("  Adding customer behavior features...")
    # Merge customer profiles to get spending patterns
    df = pd.merge(df, customer_profiles[['CUSTOMER_ID', 'mean_amount', 'std_amount']], 
                 on='CUSTOMER_ID', how='left')
    
    # Abnormal amount ratios
    df['amount_mean_ratio'] = df['TX_AMOUNT'] / df['mean_amount']
    df['amount_std_ratio'] = (df['TX_AMOUNT'] - df['mean_amount']) / df['std_amount'] 
    
    # Transaction velocity (time since last transaction)
    df['prev_tx_datetime'] = df.groupby('CUSTOMER_ID')['TX_DATETIME'].shift(1)
    df['time_since_last_tx'] = (df['TX_DATETIME'] - df['prev_tx_datetime'])
    df['time_since_last_tx_hours'] = df['time_since_last_tx'].dt.total_seconds() / 3600
    
    # Fill first transaction NaN values
    med_time = df['time_since_last_tx_hours'].median()
    df['time_since_last_tx_hours'] = df['time_since_last_tx_hours'].fillna(med_time)
    
    # High velocity flag (transactions close together)
    df['is_high_velocity'] = (df['time_since_last_tx_hours'] < 1).astype(int)
    
    # 3. TERMINAL FEATURES
    print("  Adding terminal features...")
    # Merge terminal data
    df = pd.merge(df, terminal_profiles[['TERMINAL_ID', 'terminal_type', 'x_terminal_id', 'y_terminal_id']], 
                 on='TERMINAL_ID', how='left')
    
    # One-hot encode terminal type
    terminal_dummies = pd.get_dummies(df['terminal_type'], prefix='terminal')
    df = pd.concat([df, terminal_dummies], axis=1)
    
    # Terminal risk score based on historical fraud
    terminal_risk = df.groupby('TERMINAL_ID').agg(
        terminal_tx_count=('TX_FRAUD', 'count'),
        terminal_fraud_count=('TX_FRAUD', 'sum')
    ).reset_index()
    
    # Calculate risk with Bayesian adjustment (add pseudocounts to avoid 0/0)
    terminal_risk['terminal_risk_score'] = (terminal_risk['terminal_fraud_count'] + 1) / (terminal_risk['terminal_tx_count'] + 10)
    df = pd.merge(df, terminal_risk[['TERMINAL_ID', 'terminal_risk_score', 'terminal_tx_count']], 
                 on='TERMINAL_ID', how='left')
    
    # Flag for rarely used terminals (potential fraud risk)
    df['is_rare_terminal'] = (df['terminal_tx_count'] < 5).astype(int)
    
    # 4. CUSTOMER-TERMINAL INTERACTION FEATURES
    print("  Adding customer-terminal interaction features...")
    # How often has this customer used this terminal before?
    tx_ct_pairs = df.groupby(['CUSTOMER_ID', 'TERMINAL_ID']).size().reset_index(name='ct_pair_count')
    df = pd.merge(df, tx_ct_pairs, on=['CUSTOMER_ID', 'TERMINAL_ID'], how='left')
    
    # First time customer is using this terminal?
    df['is_first_tx_terminal'] = (df['ct_pair_count'] == 1).astype(int)
    
    # Calculate distance between customer and terminal
    df = pd.merge(df, customer_profiles[['CUSTOMER_ID', 'x_customer_id', 'y_customer_id']], 
                 on='CUSTOMER_ID', how='left')
    
    df['customer_terminal_distance'] = np.sqrt(
        (df['x_customer_id'] - df['x_terminal_id'])**2 + 
        (df['y_customer_id'] - df['y_terminal_id'])**2
    )
    
    # 5. FRAUD PATTERN SPECIFIC FEATURES
    print("  Adding fraud pattern-specific features...")
    # Card-not-present (CNP) proxy - online terminals during night hours
    df['is_night_online'] = ((df['is_night'] == 1) & (df['terminal_type'] == 'online')).astype(int)
    
    # Calculate rapid succession transactions (for cash-out fraud)
    # For simplicity, we'll define this at the customer level, not transaction level
    customer_tx_counts = df.groupby(['CUSTOMER_ID', df['TX_DATETIME'].dt.date]).size().reset_index(name='txs_same_day')
    df = pd.merge(df, 
                 customer_tx_counts, 
                 left_on=['CUSTOMER_ID', df['TX_DATETIME'].dt.date], 
                 right_on=['CUSTOMER_ID', 'TX_DATETIME'],
                 how='left')
    
    df['is_high_daily_volume'] = (df['txs_same_day'] > 3).astype(int)
    
    # Drop intermediate columns and keep only features 
    cols_to_drop = [
        'prev_tx_datetime', 'time_since_last_tx', 
        'TX_TIME_SECONDS', 'TX_TIME_DAYS',
        'x_customer_id', 'y_customer_id', 'x_terminal_id', 'y_terminal_id',
        'terminal_type',
        'txs_same_day',
        'TX_DATETIME'
    ]
    
    # Drop columns that exist
    df = df.drop([col for col in cols_to_drop if col in df.columns], axis=1)
    
    print(f"  Created {df.shape[1]} features from {transactions.shape[1]} original columns")
    
    return df

def train_evaluate_models(feature_df):
    """Train and evaluate multiple fraud detection models"""
    print("\n--- Training and Evaluating Models ---")
    
    # Prepare features and target
    X = feature_df.drop(['TX_FRAUD', 'TX_FRAUD_SCENARIO', 'TRANSACTION_ID', 
                         'CUSTOMER_ID', 'TERMINAL_ID'], axis=1, errors='ignore')
    y = feature_df['TX_FRAUD']
    
    # List columns for checking
    print(f"Features: {X.shape[1]} columns")
    
    # Split into training and test sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
    
    print(f"Training set: {X_train.shape[0]} samples, {y_train.sum()} frauds ({y_train.mean():.2%} fraud rate)")
    print(f"Test set: {X_test.shape[0]} samples, {y_test.sum()} frauds ({y_test.mean():.2%} fraud rate)")
    
    # Preprocessing pipeline
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), X.select_dtypes(include=['int64', 'float64']).columns)
        ]
    )
    
    # Define models to evaluate
    models = {
        'Logistic Regression': LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),
        'Random Forest': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),
        'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
        'XGBoost': xgb.XGBClassifier(n_estimators=100, scale_pos_weight=y_train.value_counts()[0]/y_train.value_counts()[1], random_state=42),
        'LightGBM': lgb.LGBMClassifier(n_estimators=100, class_weight='balanced', random_state=42)
    }
    
    # Results tracking
    results = {}
    
    # Train and evaluate each model
    for name, model in models.items():
        print(f"\nTraining {name}...")
        
        # Create pipeline with SMOTE for imbalance handling
        pipeline = IMBPipeline([
            ('preprocessor', preprocessor),
            ('smote', SMOTE(random_state=42)),
            ('classifier', model)
        ])
        
        # Train the model
        pipeline.fit(X_train, y_train)
        
        # Make predictions
        y_pred = pipeline.predict(X_test)
        y_prob = pipeline.predict_proba(X_test)[:, 1]
        
        # Calculate metrics
        accuracy = (y_pred == y_test).mean()
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        auc = roc_auc_score(y_test, y_prob)
        avg_precision = average_precision_score(y_test, y_prob)
        
        # Print results
        print(f"  Accuracy: {accuracy:.4f}")
        print(f"  Precision: {precision:.4f}")
        print(f"  Recall: {recall:.4f}")
        print(f"  F1 Score: {f1:.4f}")
        print(f"  ROC AUC: {auc:.4f}")
        print(f"  Average Precision: {avg_precision:.4f}")
        
        # Print classification report
        print("\nClassification Report:")
        print(classification_report(y_test, y_pred))
        
        # Store results
        results[name] = {
            'pipeline': pipeline,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'auc': auc,
            'avg_precision': avg_precision,
            'y_prob': y_prob,
            'y_pred': y_pred
        }
    
    # Find best model based on AUC
    best_model = max(results.items(), key=lambda x: x[1]['auc'])
    print(f"\nBest model based on AUC: {best_model[0]} (AUC: {best_model[1]['auc']:.4f})")
    
    return results, X_test, y_test

def advanced_analysis(results, X_test, y_test, feature_df):
    """Perform advanced analysis on the models"""
    print("\n--- Advanced Analysis ---")
    
    # Get the best model (based on AUC)
    best_model_name = max(results.items(), key=lambda x: x[1]['auc'])[0]
    best_pipeline = results[best_model_name]['pipeline']
    best_model = best_pipeline.named_steps['classifier']
    
    print(f"Analyzing {best_model_name} model...")
    
    # Get feature importances for tree-based models
    if hasattr(best_model, 'feature_importances_'):
        # Get feature names after preprocessing
        feature_names = X_test.columns
        
        # Get feature importances
        importances = best_model.feature_importances_
        
        # Sort features by importance
        indices = np.argsort(importances)[::-1]
        
        print("\nTop 15 Most Important Features:")
        for i in range(min(15, len(feature_names))):
            print(f"  {i+1}. {feature_names[indices[i]]}: {importances[indices[i]]:.4f}")
    
    # Threshold optimization
    y_prob = results[best_model_name]['y_prob']
    
    # Calculate various metrics at different thresholds
    thresholds = np.arange(0.1, 1.0, 0.1)
    metrics = []
    
    print("\nThreshold Optimization:")
    print("  Threshold | Precision | Recall | F1 Score | Frauds Caught")
    print("  --------------------------------------------------------")
    
    for threshold in thresholds:
        y_pred_t = (y_prob >= threshold).astype(int)
        
        prec = precision_score(y_test, y_pred_t)
        rec = recall_score(y_test, y_pred_t)
        f1 = f1_score(y_test, y_pred_t)
        frauds_caught = (y_test & y_pred_t).sum()
        
        print(f"  {threshold:.1f}       | {prec:.4f}    | {rec:.4f} | {f1:.4f}    | {frauds_caught}/{y_test.sum()} ({frauds_caught/y_test.sum():.1%})")
        
        metrics.append((threshold, prec, rec, f1, frauds_caught))
    
    # Calculate cost-benefit at different thresholds
    print("\nCost-Benefit Analysis (assuming average values):")
    print("  - Average fraud amount: $100")
    print("  - Cost of false positive: $10 (customer friction, review cost)")
    print("  - Cost of false negative: $100 (fraud amount)")
    
    print("\n  Threshold | Savings | False Pos Cost | False Neg Cost | Net Benefit")
    print("  -----------------------------------------------------------------")
    
    avg_fraud_amount = 100
    false_pos_cost = 10
    false_neg_cost = avg_fraud_amount
    
    best_threshold = 0
    best_benefit = -np.inf
    
    for threshold, _, _, _, _ in metrics:
        y_pred_t = (y_prob >= threshold).astype(int)
        
        true_pos = ((y_test == 1) & (y_pred_t == 1)).sum()
        false_pos = ((y_test == 0) & (y_pred_t == 1)).sum()
        false_neg = ((y_test == 1) & (y_pred_t == 0)).sum()
        
        savings = true_pos * avg_fraud_amount
        fp_cost = false_pos * false_pos_cost
        fn_cost = false_neg * false_neg_cost
        
        net_benefit = savings - fp_cost - fn_cost
        
        print(f"  {threshold:.1f}       | ${savings:6} | ${fp_cost:13} | ${fn_cost:13} | ${net_benefit:10}")
        
        if net_benefit > best_benefit:
            best_benefit = net_benefit
            best_threshold = threshold
    
    print(f"\nOptimal threshold for maximum benefit: {best_threshold:.1f} (Net benefit: ${best_benefit:.2f})")
    
    # Save best model
    os.makedirs('models', exist_ok=True)
    with open(f'models/{best_model_name.replace(" ", "_").lower()}_model.pkl', 'wb') as f:
        pickle.dump(best_pipeline, f)
    
    print(f"\nBest model saved as models/{best_model_name.replace(' ', '_').lower()}_model.pkl")

def real_time_simulation(best_model_pipeline, feature_df):
    """Simulate real-time fraud detection system"""
    print("\n--- Real-Time Fraud Detection Simulation ---")
    
    # Create a simple class for real-time fraud detection
    class FraudDetectionSystem:
        def __init__(self, model, threshold=0.5):
            self.model = model
            self.threshold = threshold
            self.processed_count = 0
            self.fraud_detected_count = 0
        
        def process_transaction(self, transaction):
            # Simulate transaction processing
            self.processed_count += 1
            
            # Predict fraud probability
            fraud_prob = self.model.predict_proba(transaction.reshape(1, -1))[0, 1]
            is_fraud = fraud_prob >= self.threshold
            
            if is_fraud:
                self.fraud_detected_count += 1
            
            return {
                'transaction_id': self.processed_count,
                'fraud_probability': fraud_prob,
                'decision': 'REJECT' if is_fraud else 'APPROVE',
                'confidence': fraud_prob if is_fraud else 1 - fraud_prob
            }
    
    # Get model from the best pipeline
    best_pipeline = pickle.load(open('models/xgboost_model.pkl', 'rb'))
    
    # Create fraud detection system
    fraud_system = FraudDetectionSystem(best_pipeline, threshold=0.7)
    
    # Prepare test transactions (use a small sample from the feature set)
    X = feature_df.drop(['TX_FRAUD', 'TX_FRAUD_SCENARIO', 'TRANSACTION_ID', 
                         'CUSTOMER_ID', 'TERMINAL_ID'], axis=1, errors='ignore')
    y = feature_df['TX_FRAUD']
    
    # Get a small sample with mixed fraud/non-fraud
    fraud_sample = X[y == 1].sample(min(5, (y == 1).sum()), random_state=42).values
    non_fraud_sample = X[y == 0].sample(min(5, (y == 0).sum()), random_state=42).values
    
    test_transactions = np.vstack([fraud_sample, non_fraud_sample])
    true_labels = np.concatenate([np.ones(len(fraud_sample)), np.zeros(len(non_fraud_sample))])
    
    # Process each transaction and show results
    print("Processing test transactions...")
    print("-" * 80)
    print(f"{'ID':4} | {'True Label':10} | {'Decision':10} | {'Fraud Prob':10} | {'Confidence':10}")
    print("-" * 80)
    
    for i, (transaction, true_label) in enumerate(zip(test_transactions, true_labels)):
        result = fraud_system.process_transaction(transaction)
        
        print(f"{result['transaction_id']:4} | {'Fraud' if true_label == 1 else 'Legitimate':10} | "
              f"{result['decision']:10} | {result['fraud_probability']:.4f}    | {result['confidence']:.4f}")
    
    print("-" * 80)
    print(f"Processed {fraud_system.processed_count} transactions, {fraud_system.fraud_detected_count} flagged as fraud")

def main():
    """Main execution function"""
    print("\n===== PAYMENT FRAUD DETECTION ANALYSIS =====\n")
    
    # Load data
    transactions, customer_profiles, terminal_profiles = load_data()
    
    # Exploratory analysis
    tx_with_terminal = exploratory_analysis(transactions, customer_profiles, terminal_profiles)
    
    # Feature engineering
    feature_df = engineer_features(transactions, customer_profiles, terminal_profiles)
    
    # Train and evaluate models
    results, X_test, y_test = train_evaluate_models(feature_df)
    
    # Advanced analysis
    advanced_analysis(results, X_test, y_test, feature_df)
    
    # Get best model
    best_model_name = max(results.items(), key=lambda x: x[1]['auc'])[0]
    best_pipeline = results[best_model_name]['pipeline']
    
    # Save best model
    os.makedirs('models', exist_ok=True)
    with open(f'models/{best_model_name.replace(" ", "_").lower()}_model.pkl', 'wb') as f:
        pickle.dump(best_pipeline, f)
    
    # Real-time simulation
    try:
        real_time_simulation(best_pipeline, feature_df)
    except Exception as e:
        print(f"Error in real-time simulation: {str(e)}")
    
    print("\n===== ANALYSIS COMPLETE =====")

if __name__ == "__main__":
    main() 